{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Mastery_Weight_Regularization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMRU9U2fFaXtHyot7HS/Th",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EddyGiusepe/Keras_rede_neural_WEIGHT_REGULARIZATION/blob/main/ML_Mastery_Weight_Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go0o0854DuG3"
      },
      "source": [
        "# **Weight Regularization**\r\n",
        "\r\n",
        "\r\n",
        "Neste Notebook estudaremos como reduzir o **sobreajuste de uma rede neural de aprendizado profundo** usando a **regularização de peso**.\r\n",
        "\r\n",
        "Um modelo com pesos grandes é mais complexo do que um modelo com pesos menores. É um sinal de uma rede que pode ser excessivamente especializada em dados de treinamento.\r\n",
        "\r\n",
        "O algoritmo de aprendizagem pode ser atualizado para encorajar a rede a usar pequenos pesos.\r\n",
        "\r\n",
        "\r\n",
        "Uma forma de fazer isso é alterar o cálculo da <font color='orange'>função de perda (Loss)</font> usado na otimização da rede para considerar também o tamanho dos pesos. **Isso é chamado de regularização de peso ou redução de peso**.\r\n",
        "\r\n",
        "**Keras** oferece suporte à regularização de peso por meio do argumento ``kernel_regularizer`` em uma camada, que pode ser configurada para usar a norma do vetor $L1$ ou $L2$, por exemplo:\r\n",
        "\r\n",
        "model.add(Dense(500, input_dim=2, activation='relu', kernel_regularizer=l2(0.01)))\r\n",
        "\r\n",
        "​\r\n",
        "O exemplo a seguir demonstra um modelo de **Perceptron multicamadas** com redução de peso em um problema de classificação binária.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "**NOTA:**\r\n",
        "O site deste código pode ser encontrado [aqui](https://machinelearningmastery.com/better-deep-learning-neural-networks-crash-course/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hywUhvzjI5Ox"
      },
      "source": [
        "## Importamos nossas livrarias\r\n",
        "\r\n",
        "Exemplo de decaimento do pesso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kue3mGUDDIE"
      },
      "source": [
        "from sklearn.datasets import make_circles\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.regularizers import l2\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUZQzAslKRHU"
      },
      "source": [
        "## Geramos nossos Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9vQfwYdJneH"
      },
      "source": [
        "x, y = make_circles(n_samples=100, noise=0.1, random_state=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAkNdvckKz6l"
      },
      "source": [
        "## Dividimos nosso Dataset em Dados de treino e Dados de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYbCz3n0KymI"
      },
      "source": [
        "n_train = 30\r\n",
        "\r\n",
        "trainx, testx = x[:n_train, :], x[n_train:, :]\r\n",
        "trainy, testy = y[:n_train], y[n_train:]\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yLCwdXBMgty"
      },
      "source": [
        "## Definimos nosso modelo (criamos a nossa Rede Neural)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBV4PF17MgCs"
      },
      "source": [
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Dense(500, input_dim = 2, activation='relu', kernel_regularizer=l2(0.01)))\r\n",
        "\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwW3AuP6NzD4"
      },
      "source": [
        "## Compilamos nossa Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfxh09GTNyX-"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjSEefRuOX8g"
      },
      "source": [
        "## AJustamos nossa Rede Neural (fit model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNEcNLVrOWIR",
        "outputId": "ef3aaadf-e61d-4a3e-a889-1ea808b4888e"
      },
      "source": [
        "history = model.fit(trainx, trainy, validation_data=(testx, testy), epochs=450, verbose=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/450\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.7330 - accuracy: 0.5000 - val_loss: 0.7368 - val_accuracy: 0.4286\n",
            "Epoch 2/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7293 - accuracy: 0.7000 - val_loss: 0.7377 - val_accuracy: 0.4286\n",
            "Epoch 3/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.7257 - accuracy: 0.6667 - val_loss: 0.7388 - val_accuracy: 0.4571\n",
            "Epoch 4/450\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.7224 - accuracy: 0.6000 - val_loss: 0.7399 - val_accuracy: 0.4714\n",
            "Epoch 5/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.7192 - accuracy: 0.5667 - val_loss: 0.7411 - val_accuracy: 0.4714\n",
            "Epoch 6/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.7161 - accuracy: 0.5667 - val_loss: 0.7424 - val_accuracy: 0.4714\n",
            "Epoch 7/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7132 - accuracy: 0.5667 - val_loss: 0.7438 - val_accuracy: 0.4714\n",
            "Epoch 8/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7104 - accuracy: 0.5667 - val_loss: 0.7452 - val_accuracy: 0.4714\n",
            "Epoch 9/450\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.7078 - accuracy: 0.5667 - val_loss: 0.7466 - val_accuracy: 0.4714\n",
            "Epoch 10/450\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7053 - accuracy: 0.5667 - val_loss: 0.7481 - val_accuracy: 0.4714\n",
            "Epoch 11/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.7029 - accuracy: 0.5667 - val_loss: 0.7496 - val_accuracy: 0.4714\n",
            "Epoch 12/450\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7006 - accuracy: 0.5667 - val_loss: 0.7511 - val_accuracy: 0.4714\n",
            "Epoch 13/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6983 - accuracy: 0.5667 - val_loss: 0.7526 - val_accuracy: 0.4714\n",
            "Epoch 14/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6962 - accuracy: 0.5667 - val_loss: 0.7541 - val_accuracy: 0.4714\n",
            "Epoch 15/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6942 - accuracy: 0.5667 - val_loss: 0.7556 - val_accuracy: 0.4714\n",
            "Epoch 16/450\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6923 - accuracy: 0.5667 - val_loss: 0.7570 - val_accuracy: 0.4714\n",
            "Epoch 17/450\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6904 - accuracy: 0.6000 - val_loss: 0.7585 - val_accuracy: 0.4714\n",
            "Epoch 18/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6886 - accuracy: 0.6000 - val_loss: 0.7599 - val_accuracy: 0.4714\n",
            "Epoch 19/450\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6869 - accuracy: 0.6000 - val_loss: 0.7613 - val_accuracy: 0.4714\n",
            "Epoch 20/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6852 - accuracy: 0.6000 - val_loss: 0.7626 - val_accuracy: 0.4714\n",
            "Epoch 21/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6836 - accuracy: 0.6000 - val_loss: 0.7639 - val_accuracy: 0.4714\n",
            "Epoch 22/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6820 - accuracy: 0.6000 - val_loss: 0.7652 - val_accuracy: 0.4714\n",
            "Epoch 23/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6805 - accuracy: 0.6000 - val_loss: 0.7664 - val_accuracy: 0.4714\n",
            "Epoch 24/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6790 - accuracy: 0.6000 - val_loss: 0.7676 - val_accuracy: 0.4714\n",
            "Epoch 25/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6776 - accuracy: 0.6000 - val_loss: 0.7687 - val_accuracy: 0.4571\n",
            "Epoch 26/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6761 - accuracy: 0.6000 - val_loss: 0.7697 - val_accuracy: 0.4714\n",
            "Epoch 27/450\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6747 - accuracy: 0.6000 - val_loss: 0.7707 - val_accuracy: 0.4714\n",
            "Epoch 28/450\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6734 - accuracy: 0.6000 - val_loss: 0.7715 - val_accuracy: 0.4714\n",
            "Epoch 29/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6721 - accuracy: 0.6000 - val_loss: 0.7723 - val_accuracy: 0.4714\n",
            "Epoch 30/450\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6709 - accuracy: 0.6000 - val_loss: 0.7729 - val_accuracy: 0.4714\n",
            "Epoch 31/450\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6697 - accuracy: 0.6000 - val_loss: 0.7735 - val_accuracy: 0.4714\n",
            "Epoch 32/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6685 - accuracy: 0.6000 - val_loss: 0.7740 - val_accuracy: 0.4714\n",
            "Epoch 33/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6673 - accuracy: 0.5667 - val_loss: 0.7744 - val_accuracy: 0.4714\n",
            "Epoch 34/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6661 - accuracy: 0.5667 - val_loss: 0.7746 - val_accuracy: 0.4714\n",
            "Epoch 35/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6650 - accuracy: 0.5667 - val_loss: 0.7748 - val_accuracy: 0.4714\n",
            "Epoch 36/450\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6639 - accuracy: 0.5667 - val_loss: 0.7749 - val_accuracy: 0.4714\n",
            "Epoch 37/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6628 - accuracy: 0.5667 - val_loss: 0.7749 - val_accuracy: 0.4714\n",
            "Epoch 38/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6617 - accuracy: 0.6000 - val_loss: 0.7749 - val_accuracy: 0.4714\n",
            "Epoch 39/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6607 - accuracy: 0.6000 - val_loss: 0.7748 - val_accuracy: 0.4714\n",
            "Epoch 40/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6597 - accuracy: 0.6000 - val_loss: 0.7746 - val_accuracy: 0.4714\n",
            "Epoch 41/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6588 - accuracy: 0.6333 - val_loss: 0.7744 - val_accuracy: 0.4714\n",
            "Epoch 42/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6578 - accuracy: 0.6333 - val_loss: 0.7741 - val_accuracy: 0.4714\n",
            "Epoch 43/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6569 - accuracy: 0.6333 - val_loss: 0.7738 - val_accuracy: 0.4857\n",
            "Epoch 44/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6560 - accuracy: 0.6333 - val_loss: 0.7734 - val_accuracy: 0.4857\n",
            "Epoch 45/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6551 - accuracy: 0.6333 - val_loss: 0.7729 - val_accuracy: 0.4857\n",
            "Epoch 46/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6542 - accuracy: 0.6333 - val_loss: 0.7725 - val_accuracy: 0.4857\n",
            "Epoch 47/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6533 - accuracy: 0.6333 - val_loss: 0.7721 - val_accuracy: 0.4857\n",
            "Epoch 48/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6524 - accuracy: 0.6333 - val_loss: 0.7717 - val_accuracy: 0.4857\n",
            "Epoch 49/450\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6516 - accuracy: 0.6333 - val_loss: 0.7713 - val_accuracy: 0.4714\n",
            "Epoch 50/450\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6508 - accuracy: 0.6667 - val_loss: 0.7709 - val_accuracy: 0.4714\n",
            "Epoch 51/450\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.6500 - accuracy: 0.6667 - val_loss: 0.7706 - val_accuracy: 0.4714\n",
            "Epoch 52/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6492 - accuracy: 0.6667 - val_loss: 0.7704 - val_accuracy: 0.4714\n",
            "Epoch 53/450\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6484 - accuracy: 0.6667 - val_loss: 0.7702 - val_accuracy: 0.4714\n",
            "Epoch 54/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6476 - accuracy: 0.6667 - val_loss: 0.7700 - val_accuracy: 0.4714\n",
            "Epoch 55/450\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6468 - accuracy: 0.6667 - val_loss: 0.7698 - val_accuracy: 0.4714\n",
            "Epoch 56/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6460 - accuracy: 0.6667 - val_loss: 0.7697 - val_accuracy: 0.4714\n",
            "Epoch 57/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6452 - accuracy: 0.6667 - val_loss: 0.7696 - val_accuracy: 0.4714\n",
            "Epoch 58/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6444 - accuracy: 0.6667 - val_loss: 0.7696 - val_accuracy: 0.4714\n",
            "Epoch 59/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6437 - accuracy: 0.6667 - val_loss: 0.7696 - val_accuracy: 0.4714\n",
            "Epoch 60/450\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6429 - accuracy: 0.6667 - val_loss: 0.7695 - val_accuracy: 0.4714\n",
            "Epoch 61/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6422 - accuracy: 0.6667 - val_loss: 0.7695 - val_accuracy: 0.4714\n",
            "Epoch 62/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6414 - accuracy: 0.6667 - val_loss: 0.7696 - val_accuracy: 0.4714\n",
            "Epoch 63/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6407 - accuracy: 0.6667 - val_loss: 0.7696 - val_accuracy: 0.4714\n",
            "Epoch 64/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6400 - accuracy: 0.6667 - val_loss: 0.7697 - val_accuracy: 0.4714\n",
            "Epoch 65/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6392 - accuracy: 0.6667 - val_loss: 0.7697 - val_accuracy: 0.4714\n",
            "Epoch 66/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6385 - accuracy: 0.6667 - val_loss: 0.7698 - val_accuracy: 0.4714\n",
            "Epoch 67/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6378 - accuracy: 0.6667 - val_loss: 0.7699 - val_accuracy: 0.4714\n",
            "Epoch 68/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6371 - accuracy: 0.6667 - val_loss: 0.7700 - val_accuracy: 0.4714\n",
            "Epoch 69/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6364 - accuracy: 0.6667 - val_loss: 0.7701 - val_accuracy: 0.4714\n",
            "Epoch 70/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6357 - accuracy: 0.6667 - val_loss: 0.7701 - val_accuracy: 0.4714\n",
            "Epoch 71/450\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6350 - accuracy: 0.6667 - val_loss: 0.7702 - val_accuracy: 0.4714\n",
            "Epoch 72/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6343 - accuracy: 0.6667 - val_loss: 0.7703 - val_accuracy: 0.4714\n",
            "Epoch 73/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6336 - accuracy: 0.6667 - val_loss: 0.7704 - val_accuracy: 0.4714\n",
            "Epoch 74/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6329 - accuracy: 0.6667 - val_loss: 0.7705 - val_accuracy: 0.4714\n",
            "Epoch 75/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6322 - accuracy: 0.6667 - val_loss: 0.7706 - val_accuracy: 0.4714\n",
            "Epoch 76/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6315 - accuracy: 0.6667 - val_loss: 0.7708 - val_accuracy: 0.4714\n",
            "Epoch 77/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6308 - accuracy: 0.6667 - val_loss: 0.7709 - val_accuracy: 0.4714\n",
            "Epoch 78/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6302 - accuracy: 0.6667 - val_loss: 0.7710 - val_accuracy: 0.4714\n",
            "Epoch 79/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6295 - accuracy: 0.6667 - val_loss: 0.7711 - val_accuracy: 0.4714\n",
            "Epoch 80/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6288 - accuracy: 0.6667 - val_loss: 0.7713 - val_accuracy: 0.4714\n",
            "Epoch 81/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6282 - accuracy: 0.6667 - val_loss: 0.7714 - val_accuracy: 0.4714\n",
            "Epoch 82/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6275 - accuracy: 0.6667 - val_loss: 0.7716 - val_accuracy: 0.4714\n",
            "Epoch 83/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6268 - accuracy: 0.6667 - val_loss: 0.7717 - val_accuracy: 0.4714\n",
            "Epoch 84/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6261 - accuracy: 0.6667 - val_loss: 0.7718 - val_accuracy: 0.4714\n",
            "Epoch 85/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6255 - accuracy: 0.6667 - val_loss: 0.7720 - val_accuracy: 0.4714\n",
            "Epoch 86/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6248 - accuracy: 0.6667 - val_loss: 0.7721 - val_accuracy: 0.4714\n",
            "Epoch 87/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6241 - accuracy: 0.6667 - val_loss: 0.7722 - val_accuracy: 0.4714\n",
            "Epoch 88/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6235 - accuracy: 0.6667 - val_loss: 0.7723 - val_accuracy: 0.4714\n",
            "Epoch 89/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6228 - accuracy: 0.7000 - val_loss: 0.7724 - val_accuracy: 0.4714\n",
            "Epoch 90/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6221 - accuracy: 0.7000 - val_loss: 0.7724 - val_accuracy: 0.4714\n",
            "Epoch 91/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6215 - accuracy: 0.7000 - val_loss: 0.7725 - val_accuracy: 0.4714\n",
            "Epoch 92/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6208 - accuracy: 0.7000 - val_loss: 0.7725 - val_accuracy: 0.4714\n",
            "Epoch 93/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6202 - accuracy: 0.7000 - val_loss: 0.7726 - val_accuracy: 0.4714\n",
            "Epoch 94/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6195 - accuracy: 0.7000 - val_loss: 0.7726 - val_accuracy: 0.4714\n",
            "Epoch 95/450\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6189 - accuracy: 0.7000 - val_loss: 0.7726 - val_accuracy: 0.4714\n",
            "Epoch 96/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6182 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 97/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6176 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 98/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6170 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 99/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6163 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 100/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6157 - accuracy: 0.7000 - val_loss: 0.7728 - val_accuracy: 0.4714\n",
            "Epoch 101/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6151 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 102/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6144 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 103/450\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.6138 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 104/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6132 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 105/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6125 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 106/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6119 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 107/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6113 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 108/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6107 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 109/450\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6101 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 110/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6095 - accuracy: 0.7000 - val_loss: 0.7727 - val_accuracy: 0.4714\n",
            "Epoch 111/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6089 - accuracy: 0.7000 - val_loss: 0.7726 - val_accuracy: 0.4714\n",
            "Epoch 112/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6082 - accuracy: 0.7000 - val_loss: 0.7726 - val_accuracy: 0.4714\n",
            "Epoch 113/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6076 - accuracy: 0.7000 - val_loss: 0.7725 - val_accuracy: 0.4714\n",
            "Epoch 114/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6070 - accuracy: 0.7000 - val_loss: 0.7725 - val_accuracy: 0.4714\n",
            "Epoch 115/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6064 - accuracy: 0.7000 - val_loss: 0.7724 - val_accuracy: 0.4714\n",
            "Epoch 116/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6058 - accuracy: 0.7000 - val_loss: 0.7724 - val_accuracy: 0.4714\n",
            "Epoch 117/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6052 - accuracy: 0.7000 - val_loss: 0.7724 - val_accuracy: 0.4714\n",
            "Epoch 118/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6046 - accuracy: 0.7000 - val_loss: 0.7723 - val_accuracy: 0.4714\n",
            "Epoch 119/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6041 - accuracy: 0.7000 - val_loss: 0.7723 - val_accuracy: 0.4714\n",
            "Epoch 120/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6035 - accuracy: 0.7000 - val_loss: 0.7722 - val_accuracy: 0.4714\n",
            "Epoch 121/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6029 - accuracy: 0.7000 - val_loss: 0.7721 - val_accuracy: 0.4714\n",
            "Epoch 122/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6023 - accuracy: 0.7000 - val_loss: 0.7721 - val_accuracy: 0.4714\n",
            "Epoch 123/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6017 - accuracy: 0.7000 - val_loss: 0.7720 - val_accuracy: 0.4714\n",
            "Epoch 124/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6012 - accuracy: 0.7000 - val_loss: 0.7720 - val_accuracy: 0.4714\n",
            "Epoch 125/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6006 - accuracy: 0.7000 - val_loss: 0.7719 - val_accuracy: 0.4714\n",
            "Epoch 126/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6000 - accuracy: 0.7000 - val_loss: 0.7719 - val_accuracy: 0.4714\n",
            "Epoch 127/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5995 - accuracy: 0.7000 - val_loss: 0.7718 - val_accuracy: 0.4714\n",
            "Epoch 128/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5989 - accuracy: 0.7000 - val_loss: 0.7718 - val_accuracy: 0.4714\n",
            "Epoch 129/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5983 - accuracy: 0.7000 - val_loss: 0.7718 - val_accuracy: 0.4714\n",
            "Epoch 130/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5977 - accuracy: 0.7000 - val_loss: 0.7717 - val_accuracy: 0.4714\n",
            "Epoch 131/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5972 - accuracy: 0.7000 - val_loss: 0.7717 - val_accuracy: 0.4714\n",
            "Epoch 132/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5966 - accuracy: 0.7000 - val_loss: 0.7716 - val_accuracy: 0.4714\n",
            "Epoch 133/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5961 - accuracy: 0.7000 - val_loss: 0.7716 - val_accuracy: 0.4714\n",
            "Epoch 134/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5955 - accuracy: 0.7000 - val_loss: 0.7716 - val_accuracy: 0.4714\n",
            "Epoch 135/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5950 - accuracy: 0.7000 - val_loss: 0.7716 - val_accuracy: 0.4714\n",
            "Epoch 136/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5944 - accuracy: 0.7000 - val_loss: 0.7715 - val_accuracy: 0.4714\n",
            "Epoch 137/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5939 - accuracy: 0.7000 - val_loss: 0.7715 - val_accuracy: 0.4714\n",
            "Epoch 138/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5933 - accuracy: 0.7000 - val_loss: 0.7714 - val_accuracy: 0.4714\n",
            "Epoch 139/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5928 - accuracy: 0.7000 - val_loss: 0.7713 - val_accuracy: 0.4714\n",
            "Epoch 140/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5923 - accuracy: 0.7000 - val_loss: 0.7712 - val_accuracy: 0.4714\n",
            "Epoch 141/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5917 - accuracy: 0.7000 - val_loss: 0.7711 - val_accuracy: 0.4714\n",
            "Epoch 142/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5912 - accuracy: 0.7000 - val_loss: 0.7710 - val_accuracy: 0.4714\n",
            "Epoch 143/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5907 - accuracy: 0.7000 - val_loss: 0.7709 - val_accuracy: 0.4714\n",
            "Epoch 144/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5901 - accuracy: 0.7000 - val_loss: 0.7708 - val_accuracy: 0.4714\n",
            "Epoch 145/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5896 - accuracy: 0.7000 - val_loss: 0.7707 - val_accuracy: 0.4714\n",
            "Epoch 146/450\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.5891 - accuracy: 0.7000 - val_loss: 0.7706 - val_accuracy: 0.4714\n",
            "Epoch 147/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5886 - accuracy: 0.7000 - val_loss: 0.7705 - val_accuracy: 0.4714\n",
            "Epoch 148/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5880 - accuracy: 0.7000 - val_loss: 0.7705 - val_accuracy: 0.4714\n",
            "Epoch 149/450\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5875 - accuracy: 0.7000 - val_loss: 0.7704 - val_accuracy: 0.4714\n",
            "Epoch 150/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5870 - accuracy: 0.7000 - val_loss: 0.7704 - val_accuracy: 0.4714\n",
            "Epoch 151/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5865 - accuracy: 0.7000 - val_loss: 0.7703 - val_accuracy: 0.4714\n",
            "Epoch 152/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5860 - accuracy: 0.7000 - val_loss: 0.7703 - val_accuracy: 0.4714\n",
            "Epoch 153/450\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5855 - accuracy: 0.7000 - val_loss: 0.7702 - val_accuracy: 0.4714\n",
            "Epoch 154/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5850 - accuracy: 0.7000 - val_loss: 0.7701 - val_accuracy: 0.4714\n",
            "Epoch 155/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5845 - accuracy: 0.7000 - val_loss: 0.7700 - val_accuracy: 0.4714\n",
            "Epoch 156/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5840 - accuracy: 0.7000 - val_loss: 0.7699 - val_accuracy: 0.4714\n",
            "Epoch 157/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5835 - accuracy: 0.7000 - val_loss: 0.7698 - val_accuracy: 0.4857\n",
            "Epoch 158/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5830 - accuracy: 0.7000 - val_loss: 0.7697 - val_accuracy: 0.4857\n",
            "Epoch 159/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5825 - accuracy: 0.7000 - val_loss: 0.7696 - val_accuracy: 0.4857\n",
            "Epoch 160/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5820 - accuracy: 0.7000 - val_loss: 0.7695 - val_accuracy: 0.4857\n",
            "Epoch 161/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5815 - accuracy: 0.7000 - val_loss: 0.7693 - val_accuracy: 0.4857\n",
            "Epoch 162/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5810 - accuracy: 0.7000 - val_loss: 0.7692 - val_accuracy: 0.4857\n",
            "Epoch 163/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5805 - accuracy: 0.7000 - val_loss: 0.7691 - val_accuracy: 0.4857\n",
            "Epoch 164/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5800 - accuracy: 0.7000 - val_loss: 0.7690 - val_accuracy: 0.4857\n",
            "Epoch 165/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5795 - accuracy: 0.7000 - val_loss: 0.7688 - val_accuracy: 0.4857\n",
            "Epoch 166/450\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5790 - accuracy: 0.7000 - val_loss: 0.7687 - val_accuracy: 0.4857\n",
            "Epoch 167/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5785 - accuracy: 0.7000 - val_loss: 0.7684 - val_accuracy: 0.4857\n",
            "Epoch 168/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5781 - accuracy: 0.7000 - val_loss: 0.7682 - val_accuracy: 0.4857\n",
            "Epoch 169/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5776 - accuracy: 0.7000 - val_loss: 0.7681 - val_accuracy: 0.4857\n",
            "Epoch 170/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5771 - accuracy: 0.7000 - val_loss: 0.7679 - val_accuracy: 0.4857\n",
            "Epoch 171/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5766 - accuracy: 0.7000 - val_loss: 0.7679 - val_accuracy: 0.4857\n",
            "Epoch 172/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5761 - accuracy: 0.7000 - val_loss: 0.7679 - val_accuracy: 0.4857\n",
            "Epoch 173/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5757 - accuracy: 0.7000 - val_loss: 0.7678 - val_accuracy: 0.4857\n",
            "Epoch 174/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5752 - accuracy: 0.7000 - val_loss: 0.7678 - val_accuracy: 0.4857\n",
            "Epoch 175/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5747 - accuracy: 0.7000 - val_loss: 0.7677 - val_accuracy: 0.4857\n",
            "Epoch 176/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5742 - accuracy: 0.7000 - val_loss: 0.7676 - val_accuracy: 0.4857\n",
            "Epoch 177/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5738 - accuracy: 0.7000 - val_loss: 0.7675 - val_accuracy: 0.4857\n",
            "Epoch 178/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5733 - accuracy: 0.7000 - val_loss: 0.7674 - val_accuracy: 0.4857\n",
            "Epoch 179/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5728 - accuracy: 0.7000 - val_loss: 0.7674 - val_accuracy: 0.4857\n",
            "Epoch 180/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5724 - accuracy: 0.7000 - val_loss: 0.7673 - val_accuracy: 0.4857\n",
            "Epoch 181/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5719 - accuracy: 0.7000 - val_loss: 0.7673 - val_accuracy: 0.4857\n",
            "Epoch 182/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5715 - accuracy: 0.7000 - val_loss: 0.7673 - val_accuracy: 0.4857\n",
            "Epoch 183/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5710 - accuracy: 0.7000 - val_loss: 0.7673 - val_accuracy: 0.4857\n",
            "Epoch 184/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5706 - accuracy: 0.7000 - val_loss: 0.7671 - val_accuracy: 0.4857\n",
            "Epoch 185/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5701 - accuracy: 0.7333 - val_loss: 0.7671 - val_accuracy: 0.4857\n",
            "Epoch 186/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5697 - accuracy: 0.7333 - val_loss: 0.7671 - val_accuracy: 0.4857\n",
            "Epoch 187/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5692 - accuracy: 0.7333 - val_loss: 0.7671 - val_accuracy: 0.4857\n",
            "Epoch 188/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5688 - accuracy: 0.7333 - val_loss: 0.7671 - val_accuracy: 0.4857\n",
            "Epoch 189/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5683 - accuracy: 0.7333 - val_loss: 0.7670 - val_accuracy: 0.4857\n",
            "Epoch 190/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5679 - accuracy: 0.7333 - val_loss: 0.7669 - val_accuracy: 0.5000\n",
            "Epoch 191/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5674 - accuracy: 0.7333 - val_loss: 0.7668 - val_accuracy: 0.5000\n",
            "Epoch 192/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5670 - accuracy: 0.7333 - val_loss: 0.7667 - val_accuracy: 0.5000\n",
            "Epoch 193/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5666 - accuracy: 0.7333 - val_loss: 0.7665 - val_accuracy: 0.5000\n",
            "Epoch 194/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5661 - accuracy: 0.7333 - val_loss: 0.7663 - val_accuracy: 0.5000\n",
            "Epoch 195/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5657 - accuracy: 0.7333 - val_loss: 0.7662 - val_accuracy: 0.5000\n",
            "Epoch 196/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5653 - accuracy: 0.7333 - val_loss: 0.7661 - val_accuracy: 0.5000\n",
            "Epoch 197/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5648 - accuracy: 0.7333 - val_loss: 0.7660 - val_accuracy: 0.5000\n",
            "Epoch 198/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5644 - accuracy: 0.7333 - val_loss: 0.7659 - val_accuracy: 0.5000\n",
            "Epoch 199/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5640 - accuracy: 0.7333 - val_loss: 0.7657 - val_accuracy: 0.5000\n",
            "Epoch 200/450\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.5636 - accuracy: 0.7333 - val_loss: 0.7656 - val_accuracy: 0.5143\n",
            "Epoch 201/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5631 - accuracy: 0.7333 - val_loss: 0.7655 - val_accuracy: 0.5143\n",
            "Epoch 202/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5627 - accuracy: 0.7333 - val_loss: 0.7654 - val_accuracy: 0.5143\n",
            "Epoch 203/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5623 - accuracy: 0.7333 - val_loss: 0.7653 - val_accuracy: 0.5143\n",
            "Epoch 204/450\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5619 - accuracy: 0.7333 - val_loss: 0.7652 - val_accuracy: 0.5143\n",
            "Epoch 205/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5615 - accuracy: 0.7333 - val_loss: 0.7651 - val_accuracy: 0.5143\n",
            "Epoch 206/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5611 - accuracy: 0.7333 - val_loss: 0.7651 - val_accuracy: 0.5143\n",
            "Epoch 207/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5607 - accuracy: 0.7333 - val_loss: 0.7651 - val_accuracy: 0.5143\n",
            "Epoch 208/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5602 - accuracy: 0.7333 - val_loss: 0.7651 - val_accuracy: 0.5143\n",
            "Epoch 209/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5598 - accuracy: 0.7333 - val_loss: 0.7651 - val_accuracy: 0.5143\n",
            "Epoch 210/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5594 - accuracy: 0.7333 - val_loss: 0.7651 - val_accuracy: 0.5143\n",
            "Epoch 211/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5590 - accuracy: 0.7333 - val_loss: 0.7650 - val_accuracy: 0.5143\n",
            "Epoch 212/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5586 - accuracy: 0.7333 - val_loss: 0.7648 - val_accuracy: 0.5143\n",
            "Epoch 213/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5582 - accuracy: 0.7333 - val_loss: 0.7646 - val_accuracy: 0.5143\n",
            "Epoch 214/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5578 - accuracy: 0.7333 - val_loss: 0.7643 - val_accuracy: 0.5143\n",
            "Epoch 215/450\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5574 - accuracy: 0.7333 - val_loss: 0.7642 - val_accuracy: 0.5143\n",
            "Epoch 216/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5570 - accuracy: 0.7333 - val_loss: 0.7640 - val_accuracy: 0.5143\n",
            "Epoch 217/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5567 - accuracy: 0.7333 - val_loss: 0.7639 - val_accuracy: 0.5143\n",
            "Epoch 218/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5563 - accuracy: 0.7333 - val_loss: 0.7637 - val_accuracy: 0.5143\n",
            "Epoch 219/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5559 - accuracy: 0.7333 - val_loss: 0.7636 - val_accuracy: 0.5143\n",
            "Epoch 220/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5555 - accuracy: 0.7333 - val_loss: 0.7634 - val_accuracy: 0.5143\n",
            "Epoch 221/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5551 - accuracy: 0.7333 - val_loss: 0.7632 - val_accuracy: 0.5143\n",
            "Epoch 222/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5547 - accuracy: 0.7333 - val_loss: 0.7630 - val_accuracy: 0.5143\n",
            "Epoch 223/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5543 - accuracy: 0.7333 - val_loss: 0.7629 - val_accuracy: 0.5143\n",
            "Epoch 224/450\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5539 - accuracy: 0.7333 - val_loss: 0.7628 - val_accuracy: 0.5143\n",
            "Epoch 225/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5535 - accuracy: 0.7333 - val_loss: 0.7626 - val_accuracy: 0.5143\n",
            "Epoch 226/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5532 - accuracy: 0.7333 - val_loss: 0.7623 - val_accuracy: 0.5143\n",
            "Epoch 227/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5528 - accuracy: 0.7333 - val_loss: 0.7621 - val_accuracy: 0.5143\n",
            "Epoch 228/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5524 - accuracy: 0.7333 - val_loss: 0.7619 - val_accuracy: 0.5143\n",
            "Epoch 229/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5520 - accuracy: 0.7333 - val_loss: 0.7618 - val_accuracy: 0.5143\n",
            "Epoch 230/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5517 - accuracy: 0.7333 - val_loss: 0.7616 - val_accuracy: 0.5143\n",
            "Epoch 231/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5513 - accuracy: 0.7667 - val_loss: 0.7615 - val_accuracy: 0.5143\n",
            "Epoch 232/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5509 - accuracy: 0.7667 - val_loss: 0.7614 - val_accuracy: 0.5143\n",
            "Epoch 233/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5506 - accuracy: 0.7667 - val_loss: 0.7612 - val_accuracy: 0.5143\n",
            "Epoch 234/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5502 - accuracy: 0.7667 - val_loss: 0.7611 - val_accuracy: 0.5143\n",
            "Epoch 235/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5498 - accuracy: 0.7667 - val_loss: 0.7610 - val_accuracy: 0.5143\n",
            "Epoch 236/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5494 - accuracy: 0.7667 - val_loss: 0.7609 - val_accuracy: 0.5143\n",
            "Epoch 237/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5491 - accuracy: 0.7667 - val_loss: 0.7606 - val_accuracy: 0.5143\n",
            "Epoch 238/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5487 - accuracy: 0.7667 - val_loss: 0.7604 - val_accuracy: 0.5143\n",
            "Epoch 239/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5483 - accuracy: 0.7667 - val_loss: 0.7601 - val_accuracy: 0.5143\n",
            "Epoch 240/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5480 - accuracy: 0.7667 - val_loss: 0.7599 - val_accuracy: 0.5143\n",
            "Epoch 241/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5476 - accuracy: 0.7667 - val_loss: 0.7596 - val_accuracy: 0.5143\n",
            "Epoch 242/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5473 - accuracy: 0.7667 - val_loss: 0.7593 - val_accuracy: 0.5143\n",
            "Epoch 243/450\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5469 - accuracy: 0.7667 - val_loss: 0.7591 - val_accuracy: 0.5143\n",
            "Epoch 244/450\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.5465 - accuracy: 0.7667 - val_loss: 0.7590 - val_accuracy: 0.5286\n",
            "Epoch 245/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5462 - accuracy: 0.7667 - val_loss: 0.7587 - val_accuracy: 0.5286\n",
            "Epoch 246/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5458 - accuracy: 0.7667 - val_loss: 0.7585 - val_accuracy: 0.5286\n",
            "Epoch 247/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5455 - accuracy: 0.7667 - val_loss: 0.7583 - val_accuracy: 0.5143\n",
            "Epoch 248/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5451 - accuracy: 0.7667 - val_loss: 0.7581 - val_accuracy: 0.5143\n",
            "Epoch 249/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5448 - accuracy: 0.7667 - val_loss: 0.7578 - val_accuracy: 0.5143\n",
            "Epoch 250/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5444 - accuracy: 0.7667 - val_loss: 0.7576 - val_accuracy: 0.5143\n",
            "Epoch 251/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5441 - accuracy: 0.7667 - val_loss: 0.7574 - val_accuracy: 0.5143\n",
            "Epoch 252/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5437 - accuracy: 0.7667 - val_loss: 0.7571 - val_accuracy: 0.5143\n",
            "Epoch 253/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5433 - accuracy: 0.7667 - val_loss: 0.7568 - val_accuracy: 0.5143\n",
            "Epoch 254/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5430 - accuracy: 0.7667 - val_loss: 0.7565 - val_accuracy: 0.5143\n",
            "Epoch 255/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5427 - accuracy: 0.7667 - val_loss: 0.7562 - val_accuracy: 0.5143\n",
            "Epoch 256/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5423 - accuracy: 0.7667 - val_loss: 0.7560 - val_accuracy: 0.5143\n",
            "Epoch 257/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5420 - accuracy: 0.7667 - val_loss: 0.7558 - val_accuracy: 0.5143\n",
            "Epoch 258/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5416 - accuracy: 0.7667 - val_loss: 0.7555 - val_accuracy: 0.5143\n",
            "Epoch 259/450\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5413 - accuracy: 0.7667 - val_loss: 0.7552 - val_accuracy: 0.5143\n",
            "Epoch 260/450\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5409 - accuracy: 0.7667 - val_loss: 0.7551 - val_accuracy: 0.5143\n",
            "Epoch 261/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5406 - accuracy: 0.7667 - val_loss: 0.7549 - val_accuracy: 0.5143\n",
            "Epoch 262/450\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5402 - accuracy: 0.7667 - val_loss: 0.7546 - val_accuracy: 0.5143\n",
            "Epoch 263/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5399 - accuracy: 0.7667 - val_loss: 0.7544 - val_accuracy: 0.5143\n",
            "Epoch 264/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5395 - accuracy: 0.7667 - val_loss: 0.7541 - val_accuracy: 0.5143\n",
            "Epoch 265/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5392 - accuracy: 0.7667 - val_loss: 0.7538 - val_accuracy: 0.5143\n",
            "Epoch 266/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5388 - accuracy: 0.7667 - val_loss: 0.7534 - val_accuracy: 0.5286\n",
            "Epoch 267/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5385 - accuracy: 0.7667 - val_loss: 0.7531 - val_accuracy: 0.5286\n",
            "Epoch 268/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5382 - accuracy: 0.7667 - val_loss: 0.7528 - val_accuracy: 0.5286\n",
            "Epoch 269/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5378 - accuracy: 0.7667 - val_loss: 0.7525 - val_accuracy: 0.5286\n",
            "Epoch 270/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5375 - accuracy: 0.7667 - val_loss: 0.7523 - val_accuracy: 0.5286\n",
            "Epoch 271/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5371 - accuracy: 0.7667 - val_loss: 0.7521 - val_accuracy: 0.5286\n",
            "Epoch 272/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5368 - accuracy: 0.7667 - val_loss: 0.7519 - val_accuracy: 0.5286\n",
            "Epoch 273/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5365 - accuracy: 0.7667 - val_loss: 0.7517 - val_accuracy: 0.5286\n",
            "Epoch 274/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5361 - accuracy: 0.7667 - val_loss: 0.7516 - val_accuracy: 0.5429\n",
            "Epoch 275/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5358 - accuracy: 0.7667 - val_loss: 0.7514 - val_accuracy: 0.5429\n",
            "Epoch 276/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5355 - accuracy: 0.7667 - val_loss: 0.7511 - val_accuracy: 0.5429\n",
            "Epoch 277/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5351 - accuracy: 0.7667 - val_loss: 0.7508 - val_accuracy: 0.5429\n",
            "Epoch 278/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5348 - accuracy: 0.7667 - val_loss: 0.7504 - val_accuracy: 0.5429\n",
            "Epoch 279/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5344 - accuracy: 0.7667 - val_loss: 0.7500 - val_accuracy: 0.5429\n",
            "Epoch 280/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5341 - accuracy: 0.7667 - val_loss: 0.7497 - val_accuracy: 0.5429\n",
            "Epoch 281/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5338 - accuracy: 0.7667 - val_loss: 0.7495 - val_accuracy: 0.5429\n",
            "Epoch 282/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5334 - accuracy: 0.7667 - val_loss: 0.7493 - val_accuracy: 0.5571\n",
            "Epoch 283/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5331 - accuracy: 0.7667 - val_loss: 0.7491 - val_accuracy: 0.5571\n",
            "Epoch 284/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5328 - accuracy: 0.7667 - val_loss: 0.7489 - val_accuracy: 0.5571\n",
            "Epoch 285/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5324 - accuracy: 0.7667 - val_loss: 0.7486 - val_accuracy: 0.5571\n",
            "Epoch 286/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5321 - accuracy: 0.7667 - val_loss: 0.7483 - val_accuracy: 0.5571\n",
            "Epoch 287/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5318 - accuracy: 0.7667 - val_loss: 0.7479 - val_accuracy: 0.5571\n",
            "Epoch 288/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5314 - accuracy: 0.7667 - val_loss: 0.7475 - val_accuracy: 0.5714\n",
            "Epoch 289/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5311 - accuracy: 0.7667 - val_loss: 0.7471 - val_accuracy: 0.5714\n",
            "Epoch 290/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5308 - accuracy: 0.7667 - val_loss: 0.7467 - val_accuracy: 0.5857\n",
            "Epoch 291/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5305 - accuracy: 0.7667 - val_loss: 0.7464 - val_accuracy: 0.5857\n",
            "Epoch 292/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5301 - accuracy: 0.7667 - val_loss: 0.7462 - val_accuracy: 0.5857\n",
            "Epoch 293/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5298 - accuracy: 0.7667 - val_loss: 0.7462 - val_accuracy: 0.5857\n",
            "Epoch 294/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5295 - accuracy: 0.7667 - val_loss: 0.7461 - val_accuracy: 0.5857\n",
            "Epoch 295/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5291 - accuracy: 0.7667 - val_loss: 0.7459 - val_accuracy: 0.5857\n",
            "Epoch 296/450\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5288 - accuracy: 0.7667 - val_loss: 0.7455 - val_accuracy: 0.5857\n",
            "Epoch 297/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5284 - accuracy: 0.7667 - val_loss: 0.7451 - val_accuracy: 0.5857\n",
            "Epoch 298/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5281 - accuracy: 0.7667 - val_loss: 0.7447 - val_accuracy: 0.5857\n",
            "Epoch 299/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5278 - accuracy: 0.7667 - val_loss: 0.7442 - val_accuracy: 0.5857\n",
            "Epoch 300/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5275 - accuracy: 0.7667 - val_loss: 0.7438 - val_accuracy: 0.5857\n",
            "Epoch 301/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5271 - accuracy: 0.7667 - val_loss: 0.7434 - val_accuracy: 0.5857\n",
            "Epoch 302/450\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5268 - accuracy: 0.7667 - val_loss: 0.7431 - val_accuracy: 0.5857\n",
            "Epoch 303/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5265 - accuracy: 0.7667 - val_loss: 0.7427 - val_accuracy: 0.5857\n",
            "Epoch 304/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5262 - accuracy: 0.7667 - val_loss: 0.7425 - val_accuracy: 0.5857\n",
            "Epoch 305/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5258 - accuracy: 0.7667 - val_loss: 0.7423 - val_accuracy: 0.5857\n",
            "Epoch 306/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5255 - accuracy: 0.7667 - val_loss: 0.7421 - val_accuracy: 0.5857\n",
            "Epoch 307/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5252 - accuracy: 0.7667 - val_loss: 0.7419 - val_accuracy: 0.5857\n",
            "Epoch 308/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5249 - accuracy: 0.7667 - val_loss: 0.7417 - val_accuracy: 0.5857\n",
            "Epoch 309/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5245 - accuracy: 0.7667 - val_loss: 0.7413 - val_accuracy: 0.5857\n",
            "Epoch 310/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5242 - accuracy: 0.7667 - val_loss: 0.7407 - val_accuracy: 0.5857\n",
            "Epoch 311/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5239 - accuracy: 0.7667 - val_loss: 0.7402 - val_accuracy: 0.5857\n",
            "Epoch 312/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5236 - accuracy: 0.7667 - val_loss: 0.7397 - val_accuracy: 0.5857\n",
            "Epoch 313/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5232 - accuracy: 0.7667 - val_loss: 0.7394 - val_accuracy: 0.5857\n",
            "Epoch 314/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5229 - accuracy: 0.7667 - val_loss: 0.7392 - val_accuracy: 0.5857\n",
            "Epoch 315/450\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5226 - accuracy: 0.7667 - val_loss: 0.7389 - val_accuracy: 0.5857\n",
            "Epoch 316/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5223 - accuracy: 0.7667 - val_loss: 0.7387 - val_accuracy: 0.5857\n",
            "Epoch 317/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5219 - accuracy: 0.7667 - val_loss: 0.7385 - val_accuracy: 0.5857\n",
            "Epoch 318/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5216 - accuracy: 0.7667 - val_loss: 0.7381 - val_accuracy: 0.5857\n",
            "Epoch 319/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5213 - accuracy: 0.7667 - val_loss: 0.7377 - val_accuracy: 0.5857\n",
            "Epoch 320/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5210 - accuracy: 0.7667 - val_loss: 0.7371 - val_accuracy: 0.5857\n",
            "Epoch 321/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5207 - accuracy: 0.7667 - val_loss: 0.7365 - val_accuracy: 0.5857\n",
            "Epoch 322/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5203 - accuracy: 0.7667 - val_loss: 0.7360 - val_accuracy: 0.5857\n",
            "Epoch 323/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5200 - accuracy: 0.7667 - val_loss: 0.7356 - val_accuracy: 0.6000\n",
            "Epoch 324/450\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.5197 - accuracy: 0.7667 - val_loss: 0.7354 - val_accuracy: 0.6000\n",
            "Epoch 325/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5194 - accuracy: 0.7667 - val_loss: 0.7353 - val_accuracy: 0.6000\n",
            "Epoch 326/450\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5190 - accuracy: 0.7667 - val_loss: 0.7352 - val_accuracy: 0.6000\n",
            "Epoch 327/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5187 - accuracy: 0.7667 - val_loss: 0.7352 - val_accuracy: 0.6000\n",
            "Epoch 328/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5184 - accuracy: 0.7667 - val_loss: 0.7349 - val_accuracy: 0.6000\n",
            "Epoch 329/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5181 - accuracy: 0.7667 - val_loss: 0.7345 - val_accuracy: 0.6000\n",
            "Epoch 330/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5178 - accuracy: 0.7667 - val_loss: 0.7338 - val_accuracy: 0.6143\n",
            "Epoch 331/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5174 - accuracy: 0.7667 - val_loss: 0.7332 - val_accuracy: 0.6143\n",
            "Epoch 332/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5171 - accuracy: 0.7667 - val_loss: 0.7328 - val_accuracy: 0.6143\n",
            "Epoch 333/450\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.5168 - accuracy: 0.7667 - val_loss: 0.7325 - val_accuracy: 0.6143\n",
            "Epoch 334/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5165 - accuracy: 0.7667 - val_loss: 0.7321 - val_accuracy: 0.6143\n",
            "Epoch 335/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5162 - accuracy: 0.7667 - val_loss: 0.7319 - val_accuracy: 0.6143\n",
            "Epoch 336/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5158 - accuracy: 0.7667 - val_loss: 0.7316 - val_accuracy: 0.6143\n",
            "Epoch 337/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5155 - accuracy: 0.7667 - val_loss: 0.7311 - val_accuracy: 0.6143\n",
            "Epoch 338/450\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.5152 - accuracy: 0.7667 - val_loss: 0.7307 - val_accuracy: 0.6143\n",
            "Epoch 339/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5149 - accuracy: 0.7667 - val_loss: 0.7303 - val_accuracy: 0.6143\n",
            "Epoch 340/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5146 - accuracy: 0.7667 - val_loss: 0.7299 - val_accuracy: 0.6143\n",
            "Epoch 341/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5142 - accuracy: 0.7667 - val_loss: 0.7296 - val_accuracy: 0.6143\n",
            "Epoch 342/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5139 - accuracy: 0.7667 - val_loss: 0.7294 - val_accuracy: 0.6143\n",
            "Epoch 343/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5136 - accuracy: 0.7667 - val_loss: 0.7290 - val_accuracy: 0.6143\n",
            "Epoch 344/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5133 - accuracy: 0.8000 - val_loss: 0.7285 - val_accuracy: 0.6143\n",
            "Epoch 345/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5130 - accuracy: 0.8000 - val_loss: 0.7279 - val_accuracy: 0.6143\n",
            "Epoch 346/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5127 - accuracy: 0.8000 - val_loss: 0.7274 - val_accuracy: 0.6143\n",
            "Epoch 347/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5123 - accuracy: 0.8000 - val_loss: 0.7270 - val_accuracy: 0.6143\n",
            "Epoch 348/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5120 - accuracy: 0.8000 - val_loss: 0.7266 - val_accuracy: 0.6143\n",
            "Epoch 349/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5117 - accuracy: 0.8000 - val_loss: 0.7264 - val_accuracy: 0.6143\n",
            "Epoch 350/450\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.5114 - accuracy: 0.8000 - val_loss: 0.7262 - val_accuracy: 0.6143\n",
            "Epoch 351/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5111 - accuracy: 0.8000 - val_loss: 0.7259 - val_accuracy: 0.6143\n",
            "Epoch 352/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5108 - accuracy: 0.8000 - val_loss: 0.7255 - val_accuracy: 0.6143\n",
            "Epoch 353/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5104 - accuracy: 0.8000 - val_loss: 0.7250 - val_accuracy: 0.6143\n",
            "Epoch 354/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5101 - accuracy: 0.8000 - val_loss: 0.7245 - val_accuracy: 0.6143\n",
            "Epoch 355/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5098 - accuracy: 0.8000 - val_loss: 0.7241 - val_accuracy: 0.6143\n",
            "Epoch 356/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5095 - accuracy: 0.8000 - val_loss: 0.7237 - val_accuracy: 0.6143\n",
            "Epoch 357/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5092 - accuracy: 0.8000 - val_loss: 0.7232 - val_accuracy: 0.6143\n",
            "Epoch 358/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5088 - accuracy: 0.8000 - val_loss: 0.7229 - val_accuracy: 0.6143\n",
            "Epoch 359/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5085 - accuracy: 0.8000 - val_loss: 0.7226 - val_accuracy: 0.6143\n",
            "Epoch 360/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5082 - accuracy: 0.8000 - val_loss: 0.7223 - val_accuracy: 0.6143\n",
            "Epoch 361/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5079 - accuracy: 0.8000 - val_loss: 0.7218 - val_accuracy: 0.6143\n",
            "Epoch 362/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5076 - accuracy: 0.8333 - val_loss: 0.7213 - val_accuracy: 0.6143\n",
            "Epoch 363/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5073 - accuracy: 0.8333 - val_loss: 0.7207 - val_accuracy: 0.6143\n",
            "Epoch 364/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5070 - accuracy: 0.8333 - val_loss: 0.7203 - val_accuracy: 0.6143\n",
            "Epoch 365/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5066 - accuracy: 0.8333 - val_loss: 0.7200 - val_accuracy: 0.6143\n",
            "Epoch 366/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.5063 - accuracy: 0.8333 - val_loss: 0.7196 - val_accuracy: 0.6143\n",
            "Epoch 367/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5060 - accuracy: 0.8333 - val_loss: 0.7192 - val_accuracy: 0.6143\n",
            "Epoch 368/450\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.5057 - accuracy: 0.8333 - val_loss: 0.7189 - val_accuracy: 0.6143\n",
            "Epoch 369/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5054 - accuracy: 0.8333 - val_loss: 0.7185 - val_accuracy: 0.6143\n",
            "Epoch 370/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.5051 - accuracy: 0.8333 - val_loss: 0.7181 - val_accuracy: 0.6143\n",
            "Epoch 371/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5048 - accuracy: 0.8333 - val_loss: 0.7177 - val_accuracy: 0.6143\n",
            "Epoch 372/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5044 - accuracy: 0.8333 - val_loss: 0.7172 - val_accuracy: 0.6143\n",
            "Epoch 373/450\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5041 - accuracy: 0.8333 - val_loss: 0.7168 - val_accuracy: 0.6143\n",
            "Epoch 374/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5038 - accuracy: 0.8333 - val_loss: 0.7163 - val_accuracy: 0.6143\n",
            "Epoch 375/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5035 - accuracy: 0.8333 - val_loss: 0.7158 - val_accuracy: 0.6143\n",
            "Epoch 376/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5032 - accuracy: 0.8333 - val_loss: 0.7155 - val_accuracy: 0.6143\n",
            "Epoch 377/450\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.5029 - accuracy: 0.8333 - val_loss: 0.7153 - val_accuracy: 0.6143\n",
            "Epoch 378/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5026 - accuracy: 0.8333 - val_loss: 0.7150 - val_accuracy: 0.6143\n",
            "Epoch 379/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5023 - accuracy: 0.8333 - val_loss: 0.7146 - val_accuracy: 0.6143\n",
            "Epoch 380/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5019 - accuracy: 0.8333 - val_loss: 0.7142 - val_accuracy: 0.6143\n",
            "Epoch 381/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5016 - accuracy: 0.8333 - val_loss: 0.7136 - val_accuracy: 0.6143\n",
            "Epoch 382/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5013 - accuracy: 0.8333 - val_loss: 0.7131 - val_accuracy: 0.6143\n",
            "Epoch 383/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5010 - accuracy: 0.8333 - val_loss: 0.7126 - val_accuracy: 0.6143\n",
            "Epoch 384/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5007 - accuracy: 0.8333 - val_loss: 0.7122 - val_accuracy: 0.6143\n",
            "Epoch 385/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5004 - accuracy: 0.8333 - val_loss: 0.7117 - val_accuracy: 0.6143\n",
            "Epoch 386/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5001 - accuracy: 0.8333 - val_loss: 0.7113 - val_accuracy: 0.6143\n",
            "Epoch 387/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4998 - accuracy: 0.8333 - val_loss: 0.7110 - val_accuracy: 0.6143\n",
            "Epoch 388/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.8333 - val_loss: 0.7107 - val_accuracy: 0.6143\n",
            "Epoch 389/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4991 - accuracy: 0.8333 - val_loss: 0.7104 - val_accuracy: 0.6143\n",
            "Epoch 390/450\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.4988 - accuracy: 0.8333 - val_loss: 0.7100 - val_accuracy: 0.6143\n",
            "Epoch 391/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.4985 - accuracy: 0.8333 - val_loss: 0.7096 - val_accuracy: 0.6143\n",
            "Epoch 392/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4982 - accuracy: 0.8333 - val_loss: 0.7090 - val_accuracy: 0.6143\n",
            "Epoch 393/450\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4979 - accuracy: 0.8333 - val_loss: 0.7083 - val_accuracy: 0.6143\n",
            "Epoch 394/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.4976 - accuracy: 0.8333 - val_loss: 0.7077 - val_accuracy: 0.6143\n",
            "Epoch 395/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4973 - accuracy: 0.8333 - val_loss: 0.7073 - val_accuracy: 0.6143\n",
            "Epoch 396/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4970 - accuracy: 0.8333 - val_loss: 0.7069 - val_accuracy: 0.6143\n",
            "Epoch 397/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4967 - accuracy: 0.8333 - val_loss: 0.7068 - val_accuracy: 0.6143\n",
            "Epoch 398/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4964 - accuracy: 0.8333 - val_loss: 0.7066 - val_accuracy: 0.6143\n",
            "Epoch 399/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.4961 - accuracy: 0.8333 - val_loss: 0.7064 - val_accuracy: 0.6143\n",
            "Epoch 400/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.4958 - accuracy: 0.8333 - val_loss: 0.7061 - val_accuracy: 0.6143\n",
            "Epoch 401/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.4954 - accuracy: 0.8333 - val_loss: 0.7058 - val_accuracy: 0.6143\n",
            "Epoch 402/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4951 - accuracy: 0.8333 - val_loss: 0.7052 - val_accuracy: 0.6143\n",
            "Epoch 403/450\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.4948 - accuracy: 0.8333 - val_loss: 0.7045 - val_accuracy: 0.6143\n",
            "Epoch 404/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4945 - accuracy: 0.8333 - val_loss: 0.7038 - val_accuracy: 0.6143\n",
            "Epoch 405/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.4942 - accuracy: 0.8333 - val_loss: 0.7032 - val_accuracy: 0.6143\n",
            "Epoch 406/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4939 - accuracy: 0.8333 - val_loss: 0.7027 - val_accuracy: 0.6143\n",
            "Epoch 407/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4936 - accuracy: 0.8333 - val_loss: 0.7023 - val_accuracy: 0.6143\n",
            "Epoch 408/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4933 - accuracy: 0.8333 - val_loss: 0.7020 - val_accuracy: 0.6143\n",
            "Epoch 409/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4930 - accuracy: 0.8333 - val_loss: 0.7017 - val_accuracy: 0.6143\n",
            "Epoch 410/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.4927 - accuracy: 0.8333 - val_loss: 0.7015 - val_accuracy: 0.6143\n",
            "Epoch 411/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.4924 - accuracy: 0.8333 - val_loss: 0.7011 - val_accuracy: 0.6143\n",
            "Epoch 412/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.4921 - accuracy: 0.8333 - val_loss: 0.7006 - val_accuracy: 0.6143\n",
            "Epoch 413/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4918 - accuracy: 0.8333 - val_loss: 0.7002 - val_accuracy: 0.6143\n",
            "Epoch 414/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4915 - accuracy: 0.8333 - val_loss: 0.6997 - val_accuracy: 0.6143\n",
            "Epoch 415/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4912 - accuracy: 0.8333 - val_loss: 0.6992 - val_accuracy: 0.6143\n",
            "Epoch 416/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.4909 - accuracy: 0.8333 - val_loss: 0.6988 - val_accuracy: 0.6143\n",
            "Epoch 417/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4906 - accuracy: 0.8333 - val_loss: 0.6983 - val_accuracy: 0.6143\n",
            "Epoch 418/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4903 - accuracy: 0.8333 - val_loss: 0.6980 - val_accuracy: 0.6143\n",
            "Epoch 419/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4900 - accuracy: 0.8333 - val_loss: 0.6976 - val_accuracy: 0.6143\n",
            "Epoch 420/450\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4897 - accuracy: 0.8333 - val_loss: 0.6971 - val_accuracy: 0.6143\n",
            "Epoch 421/450\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.4894 - accuracy: 0.8333 - val_loss: 0.6967 - val_accuracy: 0.6143\n",
            "Epoch 422/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4891 - accuracy: 0.8333 - val_loss: 0.6964 - val_accuracy: 0.6143\n",
            "Epoch 423/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4888 - accuracy: 0.8333 - val_loss: 0.6960 - val_accuracy: 0.6143\n",
            "Epoch 424/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4885 - accuracy: 0.8333 - val_loss: 0.6957 - val_accuracy: 0.6143\n",
            "Epoch 425/450\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.4882 - accuracy: 0.8333 - val_loss: 0.6952 - val_accuracy: 0.6143\n",
            "Epoch 426/450\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.4879 - accuracy: 0.8333 - val_loss: 0.6949 - val_accuracy: 0.6143\n",
            "Epoch 427/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4876 - accuracy: 0.8333 - val_loss: 0.6945 - val_accuracy: 0.6143\n",
            "Epoch 428/450\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.4873 - accuracy: 0.8333 - val_loss: 0.6941 - val_accuracy: 0.6143\n",
            "Epoch 429/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4870 - accuracy: 0.8333 - val_loss: 0.6937 - val_accuracy: 0.6143\n",
            "Epoch 430/450\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.4867 - accuracy: 0.8333 - val_loss: 0.6933 - val_accuracy: 0.6143\n",
            "Epoch 431/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4865 - accuracy: 0.8333 - val_loss: 0.6927 - val_accuracy: 0.6143\n",
            "Epoch 432/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4862 - accuracy: 0.8333 - val_loss: 0.6922 - val_accuracy: 0.6143\n",
            "Epoch 433/450\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.4859 - accuracy: 0.8333 - val_loss: 0.6918 - val_accuracy: 0.6143\n",
            "Epoch 434/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.4856 - accuracy: 0.8333 - val_loss: 0.6914 - val_accuracy: 0.6143\n",
            "Epoch 435/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4853 - accuracy: 0.8333 - val_loss: 0.6910 - val_accuracy: 0.6143\n",
            "Epoch 436/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4850 - accuracy: 0.8333 - val_loss: 0.6905 - val_accuracy: 0.6143\n",
            "Epoch 437/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.4847 - accuracy: 0.8333 - val_loss: 0.6900 - val_accuracy: 0.6143\n",
            "Epoch 438/450\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4844 - accuracy: 0.8333 - val_loss: 0.6895 - val_accuracy: 0.6143\n",
            "Epoch 439/450\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4841 - accuracy: 0.8333 - val_loss: 0.6891 - val_accuracy: 0.6143\n",
            "Epoch 440/450\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.4838 - accuracy: 0.8333 - val_loss: 0.6887 - val_accuracy: 0.6143\n",
            "Epoch 441/450\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.4835 - accuracy: 0.8333 - val_loss: 0.6884 - val_accuracy: 0.6143\n",
            "Epoch 442/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4832 - accuracy: 0.8333 - val_loss: 0.6883 - val_accuracy: 0.6143\n",
            "Epoch 443/450\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4830 - accuracy: 0.8333 - val_loss: 0.6881 - val_accuracy: 0.6143\n",
            "Epoch 444/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4827 - accuracy: 0.8333 - val_loss: 0.6878 - val_accuracy: 0.6143\n",
            "Epoch 445/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4824 - accuracy: 0.8333 - val_loss: 0.6875 - val_accuracy: 0.6143\n",
            "Epoch 446/450\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.4821 - accuracy: 0.8333 - val_loss: 0.6870 - val_accuracy: 0.6143\n",
            "Epoch 447/450\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4818 - accuracy: 0.8333 - val_loss: 0.6864 - val_accuracy: 0.6143\n",
            "Epoch 448/450\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.4815 - accuracy: 0.8333 - val_loss: 0.6858 - val_accuracy: 0.6143\n",
            "Epoch 449/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4812 - accuracy: 0.8333 - val_loss: 0.6853 - val_accuracy: 0.6143\n",
            "Epoch 450/450\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4809 - accuracy: 0.8333 - val_loss: 0.6849 - val_accuracy: 0.6143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPRSK-DIPej7"
      },
      "source": [
        "## Avaliamos nossa Rede Neural (Evaluate the model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfKAK2k7PYwq",
        "outputId": "aed668cf-1cdb-4e47-8e94-9cad8809db2f"
      },
      "source": [
        "_, train_acc = model.evaluate(trainx, trainy, verbose=1)\r\n",
        "print(\"\")\r\n",
        "print(\"\")\r\n",
        "_, test_acc = model.evaluate(testx, testy, verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4806 - accuracy: 0.8333\n",
            "\n",
            "\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.6143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JixQ5-ReP9tM",
        "outputId": "54a140cb-e4f9-496a-82d1-be9240c5bb99"
      },
      "source": [
        "# Imprimindo esses valores:\r\n",
        "print(\" Train: %0.3f, Test: %0.3f \" % (train_acc, test_acc))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Train: 0.833, Test: 0.614 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbn7qzSBSFz1"
      },
      "source": [
        "## Graficamos as curvas de aprendizagens\r\n",
        "\r\n",
        "### Gráfico das curvas de aprendizagem da Função Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "oHVIXuKaSC3X",
        "outputId": "4eaaecfc-3911-4000-9cc1-387a5f1354d6"
      },
      "source": [
        "#pyplot.subplot(211)\r\n",
        "pyplot.title('Cross-Entropy Loss', pad=-40)\r\n",
        "pyplot.plot(history.history['loss'], label='train')\r\n",
        "pyplot.plot(history.history['val_loss'], label='test')\r\n",
        "pyplot.legend()\r\n",
        "pyplot.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_4rDgLASr8O"
      },
      "source": [
        "### Gráfico das curvas de aprendizagem da accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "_iUnGp2sSl8X",
        "outputId": "7b6451eb-8991-4bc0-94af-99d686a2a949"
      },
      "source": [
        "#pyplot.subplot(212)\r\n",
        "pyplot.title('Accuracy', pad=-40)\r\n",
        "pyplot.plot(history.history['accuracy'], label='train')\r\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\r\n",
        "pyplot.legend()\r\n",
        "pyplot.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9zJvi5RTLv6"
      },
      "source": [
        "Tenta executar o exemplo de código com e sem regularização de peso e descrever o efeito que isso tem nas curvas de aprendizado durante o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjGh6iB7S2fz"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}